{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-armed bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this lab session is to test the performance of some usual bandit algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are $k$ possible actions, $a \\in \\{ 0, 1,...,k - 1\\}$. \n",
    "\n",
    "We consider the following algorithms:\n",
    "* $\\varepsilon$-greedy\n",
    "* adaptive greedy\n",
    "* UCB\n",
    "* Thompson sampling\n",
    "\n",
    "Each algorithm returns an action $a$ based on the following inputs:\n",
    "\n",
    "| Variable   |      Type      |  Description |\n",
    "|:---|:---|:---|\n",
    "| `nb_tries` |  1D array of int of size `k` | number of tries of each action so far |\n",
    "| `cum_rewards` |    1D array of float of size `k`    |   cumulative reward of each action so far |\n",
    "| `t` | integer (optional) |    current time |\n",
    "| `param` | mixed |    parameter of the algorithm |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "**To do:**\n",
    "* Code the UCB algorithm. \n",
    "* Observe the behaviour of the algorithms, for different parameters.\n",
    "* Test the principle of \"optimism in face of uncertainty\" on the greedy policies.\n",
    "\n",
    "**Hint:** Use the `simple_test` function to test the behaviour of the algorithms for binary rewards.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eps_greedy(nb_tries, cum_rewards, param):\n",
    "    if param == None:\n",
    "        eps = 0.1\n",
    "    else:\n",
    "        eps = float(param)\n",
    "    k = np.shape(nb_tries)[0]\n",
    "    if np.sum(nb_tries) == 0 or np.random.random() < eps:\n",
    "        return np.random.randint(k)\n",
    "    else:\n",
    "        index = np.where(nb_tries > 0)[0]\n",
    "        return index[np.argmax(cum_rewards[index] / nb_tries[index])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaptive_greedy(nb_tries, cum_rewards, param):\n",
    "    if param == None:\n",
    "        c = 1.\n",
    "    else:\n",
    "        c = float(param)\n",
    "    k = np.shape(nb_tries)[0]\n",
    "    t = np.sum(nb_tries)\n",
    "    if np.sum(nb_tries) == 0 or np.random.random() < c / (c + t):\n",
    "        return np.random.randint(k)\n",
    "    else:\n",
    "        index = np.where(nb_tries > 0)[0]\n",
    "        return index[np.argmax(cum_rewards[index] / nb_tries[index])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ucb(nb_tries, cum_rewards, param):\n",
    "    if param == None:\n",
    "        c = 1. \n",
    "    else:\n",
    "        c = float(param)\n",
    "    # to be completed\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thompson(nb_tries, cum_rewards, param):\n",
    "    k = np.shape(nb_tries)[0]\n",
    "    if param == \"beta\":\n",
    "        # Beta prior\n",
    "        try:\n",
    "            samples = np.random.beta(cum_rewards + 1, nb_tries - cum_rewards + 1)\n",
    "        except:\n",
    "            samples = np.random.random(k)\n",
    "    else:\n",
    "        # Normal prior\n",
    "        samples = np.random.normal(cum_rewards / (nb_tries + 1), 1. / (nb_tries + 1))\n",
    "    return np.argmax(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action(algo, nb_tries, cum_rewards, param = None):\n",
    "    if algo == \"eps_greedy\":\n",
    "        return eps_greedy(nb_tries, cum_rewards, param)\n",
    "    elif algo == \"adaptive_greedy\":\n",
    "        return adaptive_greedy(nb_tries, cum_rewards, param)\n",
    "    elif algo == \"ucb\":\n",
    "        return ucb(nb_tries, cum_rewards, param)\n",
    "    elif algo == \"thompson\":\n",
    "        return thompson(nb_tries, cum_rewards, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bernoulli_reward(a, model_param):\n",
    "    return float(np.random.random() < model_param[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_test(algo, model_param = [0.1, 0.6, 0.3], time_horizon = 20, param = None):\n",
    "    k = len(model_param)\n",
    "    nb_tries = np.zeros(k, int)\n",
    "    cum_rewards = np.zeros(k, float)\n",
    "    print (\"action -> reward\")\n",
    "    for t in range(time_horizon):\n",
    "        a = get_action(algo, nb_tries, cum_rewards, param)\n",
    "        r = get_bernoulli_reward(a, model_param)\n",
    "        print(str(a) + \" -> \" + str(int(r)))\n",
    "        nb_tries[a] += 1\n",
    "        cum_rewards[a] += r\n",
    "    index = np.where(nb_tries > 0)[0]\n",
    "    best_action = index[np.argmax(cum_rewards[index] / nb_tries[index])]\n",
    "    print(\"Best action (estimation) = \", best_action)\n",
    "    print(\"Average reward of this action = \", cum_rewards[best_action] / nb_tries[best_action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algos = [\"eps_greedy\", \"adaptive_greedy\", \"ucb\", \"thompson\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = algos[0]\n",
    "simple_test(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regret and precision\n",
    "\n",
    "We now compare the performance of the algorithms in terms of **regret** and **precision**.\n",
    "\n",
    "We consider two models: Bernoulli rewards and normal rewards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reward(a, model, model_param):\n",
    "    if model == \"bernoulli\":\n",
    "        return float(np.random.random() < model_param[a])\n",
    "    elif model == \"normal\":\n",
    "        return np.random.normal(*model_param[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate(model, model_param, time_horizon, algo, param = None):\n",
    "    k = len(model_param)\n",
    "    nb_tries = np.zeros(k, int)\n",
    "    cum_rewards = np.zeros(k, float)\n",
    "    action_seq = []\n",
    "    reward_seq = []\n",
    "    for t in range(time_horizon):\n",
    "        a = get_action(algo, nb_tries, cum_rewards, param)\n",
    "        r = get_reward(a, model, model_param)\n",
    "        nb_tries[a] += 1\n",
    "        cum_rewards[a] += r\n",
    "        action_seq.append(a)\n",
    "        reward_seq.append(r)\n",
    "    return action_seq, reward_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli rewards\n",
    "model = \"bernoulli\"\n",
    "model_param = [0.1, 0.6, 0.3]\n",
    "time_horizon = 20\n",
    "algo = algos[1]\n",
    "action_seq, reward_seq = simulate(model, model_param, time_horizon, algo)\n",
    "print(action_seq)\n",
    "print(reward_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal rewards\n",
    "model = \"normal\"\n",
    "model_param = [(2,1), (2.5,1)]\n",
    "action_seq, reward_seq = simulate(model, model_param, time_horizon, algo)\n",
    "print(action_seq)\n",
    "print(reward_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**To do:**\n",
    "* Write the function `get_metrics` that returns the regret and precision throughout the run of the algorithm.\n",
    "* Observe the behaviour of each algorithm over independent runs, for both models and different instances of the model.\n",
    "* How do you explain that the regret can be negative?\n",
    "* Test the impact of the prior used by Thompson sampling\n",
    "\n",
    "**Note:** The `get_best_action` function returns the list of best actions and the corresponding expected reward.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_action(model, model_param):\n",
    "    if model == \"bernoulli\":\n",
    "        best_reward = np.max(model_param)\n",
    "        best_actions = list(np.where(model_param == best_reward)[0])\n",
    "    elif model == \"normal\":\n",
    "        means = [params[a][0] for a in range(len(model_param))]\n",
    "        best_reward = np.max(model_param)\n",
    "        best_actions = list(np.where(means == best_reward)[0])\n",
    "    return best_actions, best_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(action_seq, reward_seq, best_actions, best_reward):\n",
    "    time_horizon = len(action_seq)\n",
    "    regret = np.zeros(time_horizon, float)\n",
    "    precision = np.zeros(time_horizon, float)\n",
    "    # to be completed\n",
    "    return regret, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_metrics(metrics):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12, 4))\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Regret')\n",
    "    ax1.plot(range(time_horizon),metrics[0], color = 'b')\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.set_ylim(-0.02,1.02)\n",
    "    ax2.plot(range(time_horizon),metrics[1], color = 'b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_horizon = 10000\n",
    "model = \"bernoulli\"\n",
    "model_param = [0.2, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = algos[1]\n",
    "results = simulate(model, model_param, time_horizon,  algo)\n",
    "metrics = get_metrics(*results, *get_best_action(model, model_param))\n",
    "show_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "Finally, we provide some statistics on the performance of each algorithm for different time horizons.\n",
    "\n",
    "***\n",
    "\n",
    "**To do:**\n",
    "* Compare the performance of the algorithms.\n",
    "* What algorithm would you recommand for a time horizon $T = 1000$?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stats(nb_samples, time_periods, model, model_param, algo, param = None):\n",
    "    time_horizon = max(time_periods)\n",
    "    norm_regret_samples = [[] for t in time_periods]\n",
    "    precision_samples = [[] for t in time_periods]\n",
    "    for s in range(nb_samples):\n",
    "        results = simulate(model, model_param, time_horizon, algo, param)\n",
    "        regret, precision = get_metrics(*results, *get_best_action(model, model_param))\n",
    "        for i,t in enumerate(time_periods):\n",
    "            norm_regret_samples[i].append(regret[t - 1] / t)\n",
    "            precision_samples[i].append(precision[t - 1])\n",
    "    return norm_regret_samples, precision_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_stats(time_periods, stats):\n",
    "    meanprops = dict(marker='o', markeredgecolor='black', markerfacecolor='r')\n",
    "    medianprops = dict(linestyle='-', linewidth=2.5, color = 'b')\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12, 4))\n",
    "    ax1.boxplot(stats[0], positions = range(len(time_periods)), showfliers = False, showmeans = True, meanprops = meanprops, medianprops = medianprops)\n",
    "    ax1.axhline(linestyle = '--', color = 'r')\n",
    "    ax1.set_xticklabels(time_periods)\n",
    "    ax1.set_xlabel('Time horizon')\n",
    "    ax1.set_ylabel('Normalized regret')\n",
    "    ax2.boxplot(stats[1], positions = range(len(time_periods)), showfliers = False, showmeans = True, meanprops = meanprops, medianprops = medianprops)\n",
    "    ax2.set_ylim(-0.02,1.02)\n",
    "    ax2.axhline(y = 1, linestyle = '--', color = 'r')\n",
    "    ax2.set_xticklabels(time_periods)\n",
    "    ax2.set_xlabel('Time horizon')\n",
    "    ax2.set_ylabel('Precision')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_periods = [100,1000,5000]\n",
    "nb_samples = 100\n",
    "model = \"bernoulli\"\n",
    "model_param = [0.1, 0.2]\n",
    "algo = algos[3]\n",
    "stats = get_stats(nb_samples, time_periods, model, model_param, algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats(time_periods, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
